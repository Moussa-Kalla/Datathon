{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratégie pour Utiliser le fichie JSON avec GPT-4o en RAG\n",
    "\t1.\tIndexer les questions et réponses dans une base vectorielle (FAISS, ChromaDB).\n",
    "\t2.\tLorsqu’un utilisateur pose une question, récupérer la réponse la plus pertinente.\n",
    "\t3.\tEnvoyer la réponse trouvée + la question originale à GPT-4o pour générer une réponse contextualisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparer la Base de Données Vectorielle\n",
    "\n",
    "On va transformer les instructions et inputs en vecteurs pour effectuer des recherches de similarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "with open(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/faq.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = [entry[\"instruction\"] + \" \" + entry[\"input\"] for entry in data]\n",
    "responses = [entry[\"output\"] for entry in data]\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\",device='cpu')\n",
    "embeddings = model.encode(texts)\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "faiss.write_index(index, \"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/faq.faiss\")\n",
    "with open(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rechercher la Réponse la Plus Pertinente\n",
    "\n",
    "Quand un utilisateur pose une question, on va chercher la réponse la plus proche dans FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_faq(query):\n",
    "    query_vector = model.encode([query])  \n",
    "\n",
    "    index = faiss.read_index(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/faq.faiss\")\n",
    "    with open(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        responses = json.load(f)\n",
    "\n",
    "    _, idx = index.search(np.array(query_vector), k=1)  \n",
    "    return responses[idx[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def check_maintenance():\n",
    "    last_maintenance_date = datetime.datetime(2024, 1, 31)\n",
    "    current_date = datetime.datetime.now()\n",
    "    delta = current_date - last_maintenance_date\n",
    "\n",
    "    if delta.days > 30:\n",
    "        return \"Rappel : Une maintenance est nécessaire. Il y a plus de 30 jours depuis la dernière maintenance.\"\n",
    "    else:\n",
    "        return \"Votre fauteuil n'a pas besoin de maintenance, vous êtes à jour!\"\n",
    "check_maintenance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intégrer GPT-4o avec OpenAI\n",
    "\n",
    "Une fois qu’on a récupéré la réponse la plus pertinente, on l’envoie à GPT-4o en contexte pour une réponse plus fluide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check rapide de maintenance : \n",
      "Rappel : Une maintenance est nécessaire. Il y a plus de 30 jours depuis la dernière maintenance.\n",
      "\n",
      "Pour changer les roues d'un fauteuil roulant modèle SANGO, veuillez suivre ces étapes :\n",
      "\n",
      "1. **Préparation :** Assurez-vous d'avoir un espace de travail dégagé et de rassembler les outils nécessaires, tels qu'une clé adaptée pour les boulons de roue et éventuellement un tournevis.\n",
      "\n",
      "2. **Démontage de la roue existante :** \n",
      "   - Positionnez le fauteuil de manière stable.\n",
      "   - Repérez l'axe de fixation de la roue. Souvent, il s'agit d'une goupille ou d'un écrou. \n",
      "   - Retirez la goupille ou desserrez l'écrou à l'aide de la clé pour libérer la roue. Faites attention aux rondelles ou autres petites pièces qui pourraient être présentes.\n",
      "\n",
      "3. **Installation de la nouvelle roue :**\n",
      "   - Insérez la nouvelle roue sur l'axe.\n",
      "   - Assurez-vous que les roulements sont correctement alignés et qu'ils ne présentent pas de jeu.\n",
      "   - Fixez la roue en remettant en place la goupille ou en resserrant l'écrou avec la clé. Assurez-vous que tous les composants sont bien positionnés.\n",
      "\n",
      "4. **Vérification :** \n",
      "   - Une fois la roue installée, vérifiez qu'elle tourne librement. Il ne doit pas y avoir de résistance excessive ou de frottements anormaux. \n",
      "   - Assurez-vous qu'il n'y a pas de jeu latéral et que la roue est bien sécurisée.\n",
      "\n",
      "En suivant ces étapes pour le modèle SANGO, vous devriez être en mesure de changer les roues en toute sécurité et efficacité. Si vous rencontrez des difficultés ou si des pièces semblent endommagées, il est recommandé de consulter un professionnel ou de contacter le fabricant pour obtenir de l'aide.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from rapidfuzz import process\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def detect_model(question, models):\n",
    "    \"\"\"Détecte le modèle de fauteuil roulant avec tolérance aux fautes de frappe.\"\"\"\n",
    "    best_match, score, _ = process.extractOne(question, models, score_cutoff=50)\n",
    "    \n",
    "    if score: \n",
    "        return best_match\n",
    "    return None  \n",
    "\n",
    "def ask_gpt4o(question):\n",
    "\n",
    "    print(f\"Check rapide de maintenance : \\n{check_maintenance()}\\n\")\n",
    "\n",
    "    retrieved_answer = search_faq(question)\n",
    "\n",
    "    models = [\n",
    "        \"aviva rx40\", \"quickie q50 r\", \"permobil f5\", \"invacare tdx sp2\", \"aviva fx40\",\n",
    "        \"juvo\", \"lynx\", \"m3 corpus\", \"sango\", \"storm\", \"tdx\", \"aviva rx40 ulm\"\n",
    "    ]\n",
    "\n",
    "    question_lower = question.lower()\n",
    "\n",
    "    detected_model = detect_model(question_lower, models)\n",
    "\n",
    "    if not detected_model:\n",
    "        return \"Je n’ai pas reconnu le modèle. Pouvez-vous préciser le modèle exact du fauteuil roulant ?\"\n",
    "\n",
    "    prompt = f\"\"\"On est dans le contexte des fauteuils roulants.\n",
    "    Si aucun modèle est détecté il faut fournir une réponse générale.\n",
    "Modèle détecté : {detected_model.upper()}\n",
    "Il faut fournir une réponse en tenant compte du modèle mentionné et de la base de connaissances :\n",
    "    \n",
    "Réponse de la base : {retrieved_answer}\n",
    "\n",
    "Question : {question}\n",
    "\n",
    "Réponds avec précision en tenant compte du contexte.\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "question = \"Comment changer les roues ?\"\n",
    "print(ask_gpt4o(question))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
