{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratégie pour Utiliser le fichie JSON avec GPT-4o en RAG\n",
    "\t1.\tIndexer les questions et réponses dans une base vectorielle (FAISS, ChromaDB).\n",
    "\t2.\tLorsqu’un utilisateur pose une question, récupérer la réponse la plus pertinente.\n",
    "\t3.\tEnvoyer la réponse trouvée + la question originale à GPT-4o pour générer une réponse contextualisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparer la Base de Données Vectorielle\n",
    "\n",
    "On va transformer les instructions et inputs en vecteurs pour effectuer des recherches de similarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redaf\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] La procédure spécifiée est introuvable\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "c:\\Users\\redaf\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\redaf\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de données vectorielle créée ✅\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Charger les données du fichier JSON\n",
    "with open(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/faq.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extraire les instructions et inputs comme données à indexer\n",
    "texts = [entry[\"instruction\"] + \" \" + entry[\"input\"] for entry in data]\n",
    "responses = [entry[\"output\"] for entry in data]\n",
    "\n",
    "# Utiliser SentenceTransformer pour encoder les textes\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\",device='cpu')\n",
    "embeddings = model.encode(texts)\n",
    "\n",
    "# Créer l'index FAISS pour la recherche rapide\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# Sauvegarder l'index et les réponses\n",
    "faiss.write_index(index, \"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/faq.faiss\")\n",
    "with open(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f)\n",
    "\n",
    "print(\"Base de données vectorielle créée ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rechercher la Réponse la Plus Pertinente\n",
    "\n",
    "Quand un utilisateur pose une question, on va chercher la réponse la plus proche dans FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essuyez les pièces à l'aide d'un chiffon ou d'une brosse souple, d'agents de nettoyage ménagers ordinaires et d'eau chaude. Rincez ensuite à l'eau chaude et essuyez soigneusement les pièces avec un chiffon sec.\n"
     ]
    }
   ],
   "source": [
    "def search_faq(query):\n",
    "    query_vector = model.encode([query])  # Encoder la question\n",
    "\n",
    "    # Charger l'index et les réponses\n",
    "    index = faiss.read_index(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/faq.faiss\")\n",
    "    with open(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        responses = json.load(f)\n",
    "\n",
    "    # Trouver la réponse la plus proche\n",
    "    _, idx = index.search(np.array(query_vector), k=1)  \n",
    "    return responses[idx[0][0]]  # Retourner la meilleure réponse\n",
    "\n",
    "# Exemple de recherche\n",
    "question = \"Comment nettoyer mon fauteuil roulant électrique ?\"\n",
    "print(search_faq(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rappel : Une maintenance est nécessaire. Il y a plus de 30 jours depuis la dernière maintenance.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def check_maintenance():\n",
    "    # Exemple : Vérifier si la dernière maintenance a été effectuée il y a plus de 30 jours\n",
    "    last_maintenance_date = datetime.datetime(2024, 1, 31)  # Date de la dernière maintenance\n",
    "    current_date = datetime.datetime.now()\n",
    "    delta = current_date - last_maintenance_date\n",
    "\n",
    "    if delta.days > 30:\n",
    "        return \"Rappel : Une maintenance est nécessaire. Il y a plus de 30 jours depuis la dernière maintenance.\"\n",
    "    else:\n",
    "        return \"Votre fauteuil n'a pas besoin de maintenance, vous êtes à jour!\"\n",
    "check_maintenance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intégrer GPT-4o avec OpenAI\n",
    "\n",
    "Une fois qu’on a récupéré la réponse la plus pertinente, on l’envoie à GPT-4o en contexte pour une réponse plus fluide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check rapide de maintenance : \n",
      "Rappel : Une maintenance est nécessaire. Il y a plus de 30 jours depuis la dernière maintenance.\n",
      "\n",
      "Pour changer les roues du fauteuil roulant Storm4, il est essentiel de suivre les instructions spécifiques du fabricant pour garantir sécurité et efficacité. Voici une démarche générale à suivre :\n",
      "\n",
      "1. **Préparation :**\n",
      "   - Assurez-vous que le fauteuil roulant est sur une surface plane et stable.\n",
      "   - Engagez les freins pour éviter tout mouvement.\n",
      "\n",
      "2. **Retrait de la roue :**\n",
      "   - Si votre modèle dispose de roues à démontage rapide, appuyez sur le bouton de dégagement rapide situé au centre de la roue tout en tirant la roue vers vous.\n",
      "   - Pour les roues avec écrous, utilisez une clé pour dévisser les écrous qui maintiennent la roue en place, puis retirez la roue.\n",
      "\n",
      "3. **Installation de la nouvelle roue :**\n",
      "   - Alignez la nouvelle roue avec l’axe du fauteuil.\n",
      "   - Pour les roues à démontage rapide, insérez l’axe dans le moyeu jusqu’à ce que vous entendiez un clic indiquant que la roue est bien fixée.\n",
      "   - Pour les roues à écrous, replacez la roue sur l’axe et serrez les écrous à l’aide de la clé, en veillant à ce qu'elle soit bien centrée et stable.\n",
      "\n",
      "4. **Vérification :**\n",
      "   - Assurez-vous que la roue tourne librement et qu’elle est solidement fixée.\n",
      "   - Faites un essai en toute sécurité pour vous assurer que le fauteuil roule correctement.\n",
      "\n",
      "Il est toujours recommandé de consulter le manuel spécifique de votre modèle Storm4 ou de faire appel à un professionnel pour toute assistance ou clarification supplémentaire.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def ask_gpt4o(question):\n",
    "    # Vérifier la maintenance avant de répondre\n",
    "    print(f\"Check rapide de maintenance : \\n{check_maintenance()}\\n\")\n",
    "\n",
    "    # Cherche une réponse dans la base de connaissances\n",
    "    retrieved_answer = search_faq(question)\n",
    "\n",
    "    # Vérifie si la question mentionne un modèle de fauteuil roulant\n",
    "    models = [\"AVIVA RX40\", \"Quickie Q50 R\", \"Permobil F5\", \"Invacare TDX SP2\",\"AVIVA FX40\",\"Juvo\",\"LYNX\",\"M3 Corpus\",\"Sango\",\"Storm\",\"TDX\",\"AVIVA RX40 ULM\"]  # Liste d'exemples\n",
    "    model_mentioned = any(model in question for model in models)\n",
    "\n",
    "    if not model_mentioned:\n",
    "        return \"Pourriez-vous préciser le modèle du fauteuil roulant concerné ?\"\n",
    "\n",
    "    # Construire le prompt avec le contexte\n",
    "    prompt = f\"\"\"On est dans le contexte des fauteuils roulants.\n",
    "Il faut fournir une réponse en tenant compte du modèle mentionné et de la base de connaissances :\n",
    "    \n",
    "Réponse de la base : {retrieved_answer}\n",
    "\n",
    "Question : {question}\n",
    "\n",
    "Réponds avec précision en tenant compte du contexte.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Exemple d'utilisation\n",
    "question = \"Comment changer les roues Storm?\"\n",
    "print(ask_gpt4o(question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check rapide de maintenance : \n",
      "Rappel : Une maintenance est nécessaire. Il y a plus de 30 jours depuis la dernière maintenance.\n",
      "\n",
      "Pour changer les roues d'un fauteuil roulant modèle SANGO, veuillez suivre ces étapes :\n",
      "\n",
      "1. **Préparation :** Assurez-vous d'avoir un espace de travail dégagé et de rassembler les outils nécessaires, tels qu'une clé adaptée pour les boulons de roue et éventuellement un tournevis.\n",
      "\n",
      "2. **Démontage de la roue existante :** \n",
      "   - Positionnez le fauteuil de manière stable.\n",
      "   - Repérez l'axe de fixation de la roue. Souvent, il s'agit d'une goupille ou d'un écrou. \n",
      "   - Retirez la goupille ou desserrez l'écrou à l'aide de la clé pour libérer la roue. Faites attention aux rondelles ou autres petites pièces qui pourraient être présentes.\n",
      "\n",
      "3. **Installation de la nouvelle roue :**\n",
      "   - Insérez la nouvelle roue sur l'axe.\n",
      "   - Assurez-vous que les roulements sont correctement alignés et qu'ils ne présentent pas de jeu.\n",
      "   - Fixez la roue en remettant en place la goupille ou en resserrant l'écrou avec la clé. Assurez-vous que tous les composants sont bien positionnés.\n",
      "\n",
      "4. **Vérification :** \n",
      "   - Une fois la roue installée, vérifiez qu'elle tourne librement. Il ne doit pas y avoir de résistance excessive ou de frottements anormaux. \n",
      "   - Assurez-vous qu'il n'y a pas de jeu latéral et que la roue est bien sécurisée.\n",
      "\n",
      "En suivant ces étapes pour le modèle SANGO, vous devriez être en mesure de changer les roues en toute sécurité et efficacité. Si vous rencontrez des difficultés ou si des pièces semblent endommagées, il est recommandé de consulter un professionnel ou de contacter le fabricant pour obtenir de l'aide.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from rapidfuzz import process\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def detect_model(question, models):\n",
    "    \"\"\"Détecte le modèle de fauteuil roulant avec tolérance aux fautes de frappe.\"\"\"\n",
    "    best_match, score, _ = process.extractOne(question, models, score_cutoff=50)\n",
    "    \n",
    "    if score:  # Si un modèle proche est trouvé\n",
    "        return best_match\n",
    "    return None  # Aucun modèle trouvé\n",
    "\n",
    "def ask_gpt4o(question):\n",
    "    # Vérifier la maintenance avant de répondre\n",
    "    print(f\"Check rapide de maintenance : \\n{check_maintenance()}\\n\")\n",
    "\n",
    "    # Cherche une réponse dans la base de connaissances\n",
    "    retrieved_answer = search_faq(question)\n",
    "\n",
    "    # Liste des modèles connus (normalisés en minuscules)\n",
    "    models = [\n",
    "        \"aviva rx40\", \"quickie q50 r\", \"permobil f5\", \"invacare tdx sp2\", \"aviva fx40\",\n",
    "        \"juvo\", \"lynx\", \"m3 corpus\", \"sango\", \"storm\", \"tdx\", \"aviva rx40 ulm\"\n",
    "    ]\n",
    "\n",
    "    # Normalisation de la question (minuscules)\n",
    "    question_lower = question.lower()\n",
    "\n",
    "    # Détection du modèle\n",
    "    detected_model = detect_model(question_lower, models)\n",
    "\n",
    "    if not detected_model:\n",
    "        return \"Je n’ai pas reconnu le modèle. Pouvez-vous préciser le modèle exact du fauteuil roulant ?\"\n",
    "\n",
    "    # Construire le prompt avec le contexte\n",
    "    prompt = f\"\"\"On est dans le contexte des fauteuils roulants.\n",
    "    Si aucun modèle est détecté il faut fournir une réponse générale.\n",
    "Modèle détecté : {detected_model.upper()}\n",
    "Il faut fournir une réponse en tenant compte du modèle mentionné et de la base de connaissances :\n",
    "    \n",
    "Réponse de la base : {retrieved_answer}\n",
    "\n",
    "Question : {question}\n",
    "\n",
    "Réponds avec précision en tenant compte du contexte.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Exemple d'utilisation\n",
    "question = \"Comment changer les roues ?\"\n",
    "print(ask_gpt4o(question))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
