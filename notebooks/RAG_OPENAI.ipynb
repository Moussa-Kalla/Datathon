{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratégie pour Utiliser le fichie JSON avec GPT-4o en RAG\n",
    "\t1.\tIndexer les questions et réponses dans une base vectorielle (FAISS, ChromaDB).\n",
    "\t2.\tLorsqu’un utilisateur pose une question, récupérer la réponse la plus pertinente.\n",
    "\t3.\tEnvoyer la réponse trouvée + la question originale à GPT-4o pour générer une réponse contextualisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparer la Base de Données Vectorielle\n",
    "\n",
    "On va transformer les instructions et inputs en vecteurs pour effectuer des recherches de similarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de données vectorielle créée ✅\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Charger les données du fichier JSON\n",
    "with open(\"/Users/moussa-kalla/Datathon/data/faq.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extraire les instructions et inputs comme données à indexer\n",
    "texts = [entry[\"instruction\"] + \" \" + entry[\"input\"] for entry in data]\n",
    "responses = [entry[\"output\"] for entry in data]\n",
    "\n",
    "# Utiliser SentenceTransformer pour encoder les textes\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(texts)\n",
    "\n",
    "# Créer l'index FAISS pour la recherche rapide\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# Sauvegarder l'index et les réponses\n",
    "faiss.write_index(index, \"/Users/moussa-kalla/Datathon/data/faq.faiss\")\n",
    "with open(\"/Users/moussa-kalla/Datathon/data/responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f)\n",
    "\n",
    "print(\"Base de données vectorielle créée ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rechercher la Réponse la Plus Pertinente\n",
    "\n",
    "Quand un utilisateur pose une question, on va chercher la réponse la plus proche dans FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essuyez les pièces à l'aide d'un chiffon ou d'une brosse souple, d'agents de nettoyage ménagers ordinaires et d'eau chaude. Rincez ensuite à l'eau chaude et essuyez soigneusement les pièces avec un chiffon sec.\n"
     ]
    }
   ],
   "source": [
    "def search_faq(query):\n",
    "    query_vector = model.encode([query])  # Encoder la question\n",
    "\n",
    "    # Charger l'index et les réponses\n",
    "    index = faiss.read_index(\"/Users/moussa-kalla/Datathon/data/faq.faiss\")\n",
    "    with open(\"/Users/moussa-kalla/Datathon/data/responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        responses = json.load(f)\n",
    "\n",
    "    # Trouver la réponse la plus proche\n",
    "    _, idx = index.search(np.array(query_vector), k=1)  \n",
    "    return responses[idx[0][0]]  # Retourner la meilleure réponse\n",
    "\n",
    "# Exemple de recherche\n",
    "question = \"Comment nettoyer mon fauteuil roulant électrique ?\"\n",
    "print(search_faq(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intégrer GPT-4o avec OpenAI\n",
    "\n",
    "Une fois qu’on a récupéré la réponse la plus pertinente, on l’envoie à GPT-4o en contexte pour une réponse plus fluide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les modèles de fauteuils roulants électriques de la série Storm incluent généralement plusieurs variantes qui sont adaptées à différents besoins des utilisateurs. Parmi ces modèles, on trouve souvent :\n",
      "\n",
      "1. Storm4: Connu pour sa facilité d'entretien, comme mentionné dans votre extrait, avec un accès simplifié aux composants électroniques.\n",
      "2. Storm4 X-plore: Une version du Storm4 qui est souvent équipée de roues et de suspensions adaptées pour un usage en extérieur et sur terrains accidentés.\n",
      "3. Storm3: Un ancien modèle qui était également populaire pour sa fiabilité et ses fonctionnalités.\n",
      "\n",
      "Chaque modèle peut proposer différentes configurations et options pour s'adapter aux besoins spécifiques des utilisateurs, comme des systèmes de positionnement personnalisés, différents types de commandes ou des batteries de longue durée.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def ask_gpt4o(question):\n",
    "    retrieved_answer = search_faq(question)  # Cherche la meilleure réponse\n",
    "\n",
    "    # Construire le prompt avec le contexte\n",
    "    prompt = f\"Voici une réponse issue de la base de connaissances :\\n{retrieved_answer}\\n\\nQuestion : {question}\\nRéponds avec précision en tenant compte du contexte.\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Exemple d'utilisation\n",
    "question = \"Quels sont les modèles de fauteuil roulant électrique storm ?\"\n",
    "print(ask_gpt4o(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
