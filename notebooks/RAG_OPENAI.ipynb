{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratégie pour Utiliser le fichie JSON avec GPT-4o en RAG\n",
    "\t1.\tIndexer les questions et réponses dans une base vectorielle (FAISS, ChromaDB).\n",
    "\t2.\tLorsqu’un utilisateur pose une question, récupérer la réponse la plus pertinente.\n",
    "\t3.\tEnvoyer la réponse trouvée + la question originale à GPT-4o pour générer une réponse contextualisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparer la Base de Données Vectorielle\n",
    "\n",
    "On va transformer les instructions et inputs en vecteurs pour effectuer des recherches de similarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redaf\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] La procédure spécifiée est introuvable\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "c:\\Users\\redaf\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\redaf\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de données vectorielle créée ✅\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Charger les données du fichier JSON\n",
    "with open(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/faq.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extraire les instructions et inputs comme données à indexer\n",
    "texts = [entry[\"instruction\"] + \" \" + entry[\"input\"] for entry in data]\n",
    "responses = [entry[\"output\"] for entry in data]\n",
    "\n",
    "# Utiliser SentenceTransformer pour encoder les textes\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\",device='cpu')\n",
    "embeddings = model.encode(texts)\n",
    "\n",
    "# Créer l'index FAISS pour la recherche rapide\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# Sauvegarder l'index et les réponses\n",
    "faiss.write_index(index, \"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/faq.faiss\")\n",
    "with open(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f)\n",
    "\n",
    "print(\"Base de données vectorielle créée ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rechercher la Réponse la Plus Pertinente\n",
    "\n",
    "Quand un utilisateur pose une question, on va chercher la réponse la plus proche dans FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essuyez les pièces à l'aide d'un chiffon ou d'une brosse souple, d'agents de nettoyage ménagers ordinaires et d'eau chaude. Rincez ensuite à l'eau chaude et essuyez soigneusement les pièces avec un chiffon sec.\n"
     ]
    }
   ],
   "source": [
    "def search_faq(query):\n",
    "    query_vector = model.encode([query])  # Encoder la question\n",
    "\n",
    "    # Charger l'index et les réponses\n",
    "    index = faiss.read_index(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/faq.faiss\")\n",
    "    with open(\"C:/Users/redaf/OneDrive/Bureau/Datathonclub/Datathon/data/responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        responses = json.load(f)\n",
    "\n",
    "    # Trouver la réponse la plus proche\n",
    "    _, idx = index.search(np.array(query_vector), k=1)  \n",
    "    return responses[idx[0][0]]  # Retourner la meilleure réponse\n",
    "\n",
    "# Exemple de recherche\n",
    "question = \"Comment nettoyer mon fauteuil roulant électrique ?\"\n",
    "print(search_faq(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rappel : Une maintenance est nécessaire. Il y a plus de 30 jours depuis la dernière maintenance.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def check_maintenance():\n",
    "    # Exemple : Vérifier si la dernière maintenance a été effectuée il y a plus de 30 jours\n",
    "    last_maintenance_date = datetime.datetime(2024, 1, 31)  # Date de la dernière maintenance\n",
    "    current_date = datetime.datetime.now()\n",
    "    delta = current_date - last_maintenance_date\n",
    "\n",
    "    if delta.days > 30:\n",
    "        return \"Rappel : Une maintenance est nécessaire. Il y a plus de 30 jours depuis la dernière maintenance.\"\n",
    "    else:\n",
    "        return \"Votre fauteuil n'a pas besoin de maintenance, vous êtes à jour!\"\n",
    "check_maintenance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intégrer GPT-4o avec OpenAI\n",
    "\n",
    "Une fois qu’on a récupéré la réponse la plus pertinente, on l’envoie à GPT-4o en contexte pour une réponse plus fluide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check rapide de maintenance : \n",
      "Rappel : Une maintenance est nécessaire. Il y a plus de 30 jours depuis la dernière maintenance.\n",
      "\n",
      "Pour changer les roues du fauteuil roulant Storm4 Max, il est important de suivre les instructions spécifiques du fabricant pour garantir la sécurité et le bon fonctionnement de l'appareil. Voici une démarche générale qui peut être suivie, mais il est toujours recommandé de consulter le manuel d'utilisation du Storm4 Max ou de contacter un professionnel qualifié pour une assistance spécifique :\n",
      "\n",
      "1. **Sécurité d'abord** : Assurez-vous que le fauteuil est éteint et stable, éventuellement en utilisant une surface plane et en engageant les freins.\n",
      "\n",
      "2. **Retrait de la roue** :\n",
      "   - Si la roue est fixée par un écrou, utilisez une clé appropriée pour dévisser l'écrou qui tient la roue en place. Conservez l'écrou et les rondelles si présentes pour la réinstallation.\n",
      "   - Si le fauteuil est équipé d'un système de fixation rapide, comme un bouton-poussoir central, appuyez sur ce bouton tout en tirant la roue pour la retirer de l'axe.\n",
      "\n",
      "3. **Installation de la nouvelle roue** :\n",
      "   - Alignez le moyeu de la nouvelle roue sur l’axe.\n",
      "   - Si vous utilisez un système de déverrouillage rapide, insérez simplement la roue jusqu'à ce qu'elle s'enclenche. Si la roue est fixée par un écrou, replacez l'écrou et les rondelles sur l'axe, puis serrez bien l'écrou. Assurez-vous que la roue est solidement fixée et tourne librement sans déséquilibre.\n",
      "\n",
      "4. **Test** : Une fois les roues changées, testez le fauteuil pour vous assurer que les roues sont correctement installées et fonctionnent de manière fluide. Vérifiez également l'alignement et la stabilité.\n",
      "\n",
      "Il est conseillé de consulter un professionnel si vous avez des doutes ou si vous rencontrez des difficultés lors de l'opération.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def ask_gpt4o(question):\n",
    "    # Vérifier la maintenance avant de répondre\n",
    "    print(f\"Check rapide de maintenance : \\n{check_maintenance()}\\n\")\n",
    "\n",
    "    # Cherche une réponse dans la base de connaissances\n",
    "    retrieved_answer = search_faq(question)\n",
    "\n",
    "    # Vérifie si la question mentionne un modèle de fauteuil roulant\n",
    "    models = [\"AVIVA RX40\", \"Quickie Q50 R\", \"Permobil F5\", \"Invacare TDX SP2\",\"AVIVA FX40\",\"Juvo\",\"LYNX\",\"M3 Corpus\",\"Sango\",\"Storm\",\"TDX\",\"AVIVA RX40 ULM\"]  # Liste d'exemples\n",
    "    model_mentioned = any(model in question for model in models)\n",
    "\n",
    "    if not model_mentioned:\n",
    "        return \"Pourriez-vous préciser le modèle du fauteuil roulant concerné ?\"\n",
    "\n",
    "    # Construire le prompt avec le contexte\n",
    "    prompt = f\"\"\"On est dans le contexte des fauteuils roulants.\n",
    "Il faut fournir une réponse en tenant compte du modèle mentionné et de la base de connaissances :\n",
    "    \n",
    "Réponse de la base : {retrieved_answer}\n",
    "\n",
    "Question : {question}\n",
    "\n",
    "Réponds avec précision en tenant compte du contexte.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Exemple d'utilisation\n",
    "question = \"Comment changer les roues Storm?\"\n",
    "print(ask_gpt4o(question))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
